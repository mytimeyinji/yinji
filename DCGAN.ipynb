{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyORtEpW92yE2MXEpNc6nqW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mytimeyinji/yinji/blob/master/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srsAMNSNJI19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7d16943-63cb-4f3f-d75a-8d5e66ee5f18"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejn9EOTjJP0V",
        "colab_type": "text"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "import os \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class DCGAN():\n",
        "    def __init__(self):\n",
        "        # 输入shape\n",
        "        self.img_rows = 28\n",
        "        self.img_cols = 28\n",
        "        self.channels = 1\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        # 分十类\n",
        "        self.num_classes = 10\n",
        "        self.latent_dim = 100\n",
        "        # adam优化器\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "        # 判别模型\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "        # 生成模型\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # conbine是生成模型和判别模型的结合\n",
        "        # 判别模型的trainable为False\n",
        "        # 用于训练生成模型\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        valid = self.discriminator(img)\n",
        "\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        # 先全连接到64*7*7的维度上\n",
        "        model.add(Dense(32 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        # reshape成特征层的样式\n",
        "        model.add(Reshape((7, 7, 32)))\n",
        "\n",
        "        # 7, 7, 64\n",
        "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        # 上采样\n",
        "        # 7, 7, 64 -> 14, 14, 64\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        # 上采样\n",
        "        # 14, 14, 128 -> 28, 28, 64\n",
        "        model.add(UpSampling2D())\n",
        "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "\n",
        "        # 上采样\n",
        "        # 28, 28, 64 -> 28, 28, 1\n",
        "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "        # 28, 28, 1 -> 14, 14, 32\n",
        "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        # 14, 14, 32 -> 7, 7, 64\n",
        "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        # 7, 7, 64 -> 4, 4, 128\n",
        "        model.add(ZeroPadding2D(((0,1),(0,1))))\n",
        "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(GlobalAveragePooling2D())\n",
        "        # 全连接\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, save_interval=50):\n",
        "        # 载入数据\n",
        "        (X_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "        # 归一化\n",
        "        X_train = X_train / 127.5 - 1.\n",
        "        X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # --------------------- #\n",
        "            #  训练判别模型\n",
        "            # --------------------- #\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            imgs = X_train[idx]\n",
        "\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "            # 训练并计算loss\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ---------------------\n",
        "            #  训练生成模型\n",
        "            # ---------------------\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "            if epoch % save_interval == 0:\n",
        "                self.save_imgs(epoch)\n",
        "\n",
        "    def save_imgs(self, epoch):\n",
        "        r, c = 5, 5\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if not os.path.exists(\"./images\"):\n",
        "        os.makedirs(\"./images\")\n",
        "    dcgan = DCGAN()\n",
        "    dcgan.train(epochs=20000, batch_size=256, save_interval=50)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58AxDFSebVcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXNATkdTanZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bde4a492-7922-4cd9-81fa-97afeac49e92"
      },
      "source": [
        "!tar -zcvf /home/cai.tar.gz /content/images"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar: Removing leading `/' from member names\n",
            "/content/images/\n",
            "/content/images/mnist_950.png\n",
            "/content/images/mnist_800.png\n",
            "/content/images/mnist_350.png\n",
            "/content/images/mnist_2750.png\n",
            "/content/images/mnist_3950.png\n",
            "/content/images/mnist_3100.png\n",
            "/content/images/mnist_500.png\n",
            "/content/images/mnist_1050.png\n",
            "/content/images/mnist_2450.png\n",
            "/content/images/mnist_700.png\n",
            "/content/images/mnist_3000.png\n",
            "/content/images/mnist_2700.png\n",
            "/content/images/mnist_200.png\n",
            "/content/images/mnist_1450.png\n",
            "/content/images/mnist_3700.png\n",
            "/content/images/mnist_2000.png\n",
            "/content/images/mnist_2250.png\n",
            "/content/images/mnist_3150.png\n",
            "/content/images/mnist_3350.png\n",
            "/content/images/mnist_3050.png\n",
            "/content/images/mnist_1150.png\n",
            "/content/images/mnist_1600.png\n",
            "/content/images/mnist_850.png\n",
            "/content/images/mnist_450.png\n",
            "/content/images/mnist_2100.png\n",
            "/content/images/mnist_1550.png\n",
            "/content/images/mnist_2150.png\n",
            "/content/images/mnist_1300.png\n",
            "/content/images/mnist_4000.png\n",
            "/content/images/mnist_1200.png\n",
            "/content/images/mnist_1000.png\n",
            "/content/images/mnist_1400.png\n",
            "/content/images/mnist_400.png\n",
            "/content/images/mnist_150.png\n",
            "/content/images/mnist_1650.png\n",
            "/content/images/mnist_3550.png\n",
            "/content/images/mnist_1350.png\n",
            "/content/images/mnist_2200.png\n",
            "/content/images/mnist_3900.png\n",
            "/content/images/mnist_3200.png\n",
            "/content/images/mnist_3450.png\n",
            "/content/images/mnist_100.png\n",
            "/content/images/mnist_2500.png\n",
            "/content/images/mnist_1900.png\n",
            "/content/images/mnist_0.png\n",
            "/content/images/mnist_3300.png\n",
            "/content/images/mnist_2400.png\n",
            "/content/images/mnist_2350.png\n",
            "/content/images/mnist_3850.png\n",
            "/content/images/mnist_650.png\n",
            "/content/images/mnist_1850.png\n",
            "/content/images/mnist_2600.png\n",
            "/content/images/mnist_3400.png\n",
            "/content/images/mnist_3600.png\n",
            "/content/images/mnist_1950.png\n",
            "/content/images/mnist_3750.png\n",
            "/content/images/mnist_900.png\n",
            "/content/images/mnist_300.png\n",
            "/content/images/mnist_3800.png\n",
            "/content/images/mnist_1100.png\n",
            "/content/images/mnist_3650.png\n",
            "/content/images/mnist_550.png\n",
            "/content/images/mnist_250.png\n",
            "/content/images/mnist_1800.png\n",
            "/content/images/mnist_2900.png\n",
            "/content/images/mnist_1500.png\n",
            "/content/images/mnist_750.png\n",
            "/content/images/mnist_50.png\n",
            "/content/images/mnist_2950.png\n",
            "/content/images/mnist_3500.png\n",
            "/content/images/mnist_1700.png\n",
            "/content/images/mnist_1750.png\n",
            "/content/images/mnist_2650.png\n",
            "/content/images/mnist_4050.png\n",
            "/content/images/mnist_600.png\n",
            "/content/images/mnist_3250.png\n",
            "/content/images/mnist_2050.png\n",
            "/content/images/mnist_2300.png\n",
            "/content/images/mnist_2850.png\n",
            "/content/images/mnist_2550.png\n",
            "/content/images/mnist_1250.png\n",
            "/content/images/mnist_2800.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9G8sE6vcKSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/home/cai.tar.gz')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}