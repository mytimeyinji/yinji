{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ceshi1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUvILybAc+civmzFUaGeUA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mytimeyinji/yinji/blob/master/ceshi1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3owCHtR3eHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Copyright Â© 2017 bily     Huazhong University of Science and Technology\n",
        "#\n",
        "# Distributed under terms of the MIT license.\n",
        "\n",
        "\"\"\"Miscellaneous Utilities.\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import errno\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "from os import path as osp\n",
        "\n",
        "try:\n",
        "  import pynvml  # nvidia-ml provides utility for NVIDIA management\n",
        "\n",
        "  HAS_NVML = True\n",
        "except:\n",
        "  HAS_NVML = False\n",
        "\n",
        "\n",
        "def auto_select_gpu():\n",
        "  \"\"\"Select gpu which has largest free memory\"\"\"\n",
        "  if HAS_NVML:\n",
        "    pynvml.nvmlInit()\n",
        "    deviceCount = pynvml.nvmlDeviceGetCount()\n",
        "    largest_free_mem = 0\n",
        "    largest_free_idx = 0\n",
        "    for i in range(deviceCount):\n",
        "      handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
        "      info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "      if info.free > largest_free_mem:\n",
        "        largest_free_mem = info.free\n",
        "        largest_free_idx = i\n",
        "    pynvml.nvmlShutdown()\n",
        "    largest_free_mem = largest_free_mem / 1024. / 1024.  # Convert to MB\n",
        "\n",
        "    idx_to_gpu_id = {}\n",
        "    for i in range(deviceCount):\n",
        "      idx_to_gpu_id[i] = '{}'.format(i)\n",
        "\n",
        "    gpu_id = idx_to_gpu_id[largest_free_idx]\n",
        "    logging.info('Using largest free memory GPU {} with free memory {}MB'.format(gpu_id, largest_free_mem))\n",
        "    return gpu_id\n",
        "  else:\n",
        "    logging.info('nvidia-ml-py is not installed, automatically select gpu is disabled!')\n",
        "    return '0'\n",
        "\n",
        "\n",
        "def get_center(x):\n",
        "  return (x - 1.) / 2.\n",
        "\n",
        "\n",
        "def get(config, key, default):\n",
        "  \"\"\"Get value in config by key, use default if key is not set\n",
        "  This little function is useful for dynamical experimental settings.\n",
        "  For example, we can add a new configuration without worrying compatibility with older versions.\n",
        "  You can also achieve this by just calling config.get(key, default), but add a warning is even better : )\n",
        "  \"\"\"\n",
        "  val = config.get(key)\n",
        "  if val is None:\n",
        "    logging.warning('{} is not explicitly specified, using default value: {}'.format(key, default))\n",
        "    val = default\n",
        "  return val\n",
        "\n",
        "\n",
        "def mkdir_p(path):\n",
        "  \"\"\"mimic the behavior of mkdir -p in bash\"\"\"\n",
        "  try:\n",
        "    os.makedirs(path)\n",
        "  except OSError as exc:  # Python >2.5\n",
        "    if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
        "      pass\n",
        "    else:\n",
        "      raise\n",
        "\n",
        "\n",
        "def tryfloat(s):\n",
        "  try:\n",
        "    return float(s)\n",
        "  except:\n",
        "    return s\n",
        "\n",
        "\n",
        "def alphanum_key(s):\n",
        "  \"\"\" Turn a string into a list of string and number chunks.\n",
        "      \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "  \"\"\"\n",
        "  return [tryfloat(c) for c in re.split('([0-9.]+)', s)]\n",
        "\n",
        "\n",
        "def sort_nicely(l):\n",
        "  \"\"\"Sort the given list in the way that humans expect.\"\"\"\n",
        "  return sorted(l, key=alphanum_key)\n",
        "\n",
        "\n",
        "class Tee(object):\n",
        "  \"\"\"Mimic the behavior of tee in bash\n",
        "  From: http://web.archive.org/web/20141016185743/https://mail.python.org/pipermail/python-list/2007-May/460639.html\n",
        "  Usage:\n",
        "    tee=Tee('logfile', 'w')\n",
        "    print 'abcdefg'\n",
        "    print 'another line'\n",
        "    tee.close()\n",
        "    print 'screen only'\n",
        "    del tee # should do nothing\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, name, mode):\n",
        "    self.file = open(name, mode)\n",
        "    self.stdout = sys.stdout\n",
        "    sys.stdout = self\n",
        "\n",
        "  def close(self):\n",
        "    if self.stdout is not None:\n",
        "      sys.stdout = self.stdout\n",
        "      self.stdout = None\n",
        "    if self.file is not None:\n",
        "      self.file.close()\n",
        "      self.file = None\n",
        "\n",
        "  def write(self, data):\n",
        "    self.file.write(data)\n",
        "    self.stdout.write(data)\n",
        "\n",
        "  def flush(self):\n",
        "    self.file.flush()\n",
        "    self.stdout.flush()\n",
        "\n",
        "  def __del__(self):\n",
        "    self.close()\n",
        "\n",
        "\n",
        "def save_cfgs(train_dir, model_config, train_config, track_config):\n",
        "  \"\"\"Save all configurations in JSON format for future reference\"\"\"\n",
        "  with open(osp.join(train_dir, 'model_config.json'), 'w') as f:\n",
        "    json.dump(model_config, f, indent=2)\n",
        "  with open(osp.join(train_dir, 'train_config.json'), 'w') as f:\n",
        "    json.dump(train_config, f, indent=2)\n",
        "  with open(osp.join(train_dir, 'track_config.json'), 'w') as f:\n",
        "    json.dump(track_config, f, indent=2)\n",
        "\n",
        "\n",
        "def load_cfgs(checkpoint):\n",
        "  if osp.isdir(checkpoint):\n",
        "    train_dir = checkpoint\n",
        "  else:\n",
        "    train_dir = osp.dirname(checkpoint)\n",
        "\n",
        "  with open(osp.join(train_dir, 'model_config.json'), 'r') as f:\n",
        "    model_config = json.load(f)\n",
        "  with open(osp.join(train_dir, 'train_config.json'), 'r') as f:\n",
        "    train_config = json.load(f)\n",
        "  with open(osp.join(train_dir, 'track_config.json'), 'r') as f:\n",
        "    track_config = json.load(f)\n",
        "  return model_config, train_config, track_config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoXGaCZ_3rSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "4b77561a-30b8-40b6-d34f-fb5d03a87a03"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNAdq2sL168h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "outputId": "5f657007-24f3-457c-d236-50ef16ee3248"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = '{:.1f}'.format\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-e3e81d3ff1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mERROR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{:.1f}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'logging'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ibBefhz4koC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "f1b6717c-90d0-44a9-a9d6-23cf79fc38b8"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__ "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mU8ZXWE3y8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Copyright Â© 2017 bily     Huazhong University of Science and Technology\n",
        "#\n",
        "# Distributed under terms of the MIT license.\n",
        "\n",
        "\"\"\"Contains definitions of the network in [1].\n",
        "  [1] Bertinetto, L., et al. (2016).\n",
        "      \"Fully-Convolutional Siamese Networks for Object Tracking.\"\n",
        "      arXiv preprint arXiv:1606.09549.\n",
        "\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "\n",
        "def convolutional_alexnet_arg_scope(embed_config,\n",
        "                                    trainable=True,\n",
        "                                    is_training=False):\n",
        "  \"\"\"Defines the default arg scope.\n",
        "  Args:\n",
        "    embed_config: A dictionary which contains configurations for the embedding function.\n",
        "    trainable: If the weights in the embedding function is trainable.\n",
        "    is_training: If the embedding function is built for training.\n",
        "  Returns:\n",
        "    An `arg_scope` to use for the convolutional_alexnet models.\n",
        "  \"\"\"\n",
        "  # Only consider the model to be in training mode if it's trainable.\n",
        "  # This is vital for batch_norm since moving_mean and moving_variance\n",
        "  # will get updated even if not trainable.\n",
        "  is_model_training = trainable and is_training\n",
        "\n",
        "  if get(embed_config, 'use_bn', True):\n",
        "    batch_norm_scale = get(embed_config, 'bn_scale', True)\n",
        "    batch_norm_decay = 1 - get(embed_config, 'bn_momentum', 3e-4)\n",
        "    batch_norm_epsilon = get(embed_config, 'bn_epsilon', 1e-6)\n",
        "    batch_norm_params = {\n",
        "      \"scale\": batch_norm_scale,\n",
        "      # Decay for the moving averages.\n",
        "      \"decay\": batch_norm_decay,\n",
        "      # Epsilon to prevent 0s in variance.\n",
        "      \"epsilon\": batch_norm_epsilon,\n",
        "      \"trainable\": trainable,\n",
        "      \"is_training\": is_model_training,\n",
        "      # Collection containing the moving mean and moving variance.\n",
        "      \"variables_collections\": {\n",
        "        \"beta\": None,\n",
        "        \"gamma\": None,\n",
        "        \"moving_mean\": [\"moving_vars\"],\n",
        "        \"moving_variance\": [\"moving_vars\"],\n",
        "      },\n",
        "      'updates_collections': None,  # Ensure that updates are done within a frame\n",
        "    }\n",
        "    normalizer_fn = slim.batch_norm\n",
        "  else:\n",
        "    batch_norm_params = {}\n",
        "    normalizer_fn = None\n",
        "\n",
        "  weight_decay = get(embed_config, 'weight_decay', 5e-4)\n",
        "  if trainable:\n",
        "    weights_regularizer = slim.l2_regularizer(weight_decay)\n",
        "  else:\n",
        "    weights_regularizer = None\n",
        "\n",
        "  init_method = get(embed_config, 'init_method', 'kaiming_normal')\n",
        "  if is_model_training:\n",
        "    logging.info('embedding init method -- {}'.format(init_method))\n",
        "  if init_method == 'kaiming_normal':\n",
        "    # The same setting as siamese-fc\n",
        "    initializer = slim.variance_scaling_initializer(factor=2.0, mode='FAN_OUT', uniform=False)\n",
        "  else:\n",
        "    initializer = slim.xavier_initializer()\n",
        "\n",
        "  with slim.arg_scope(\n",
        "      [slim.conv2d],\n",
        "      weights_regularizer=weights_regularizer,\n",
        "      weights_initializer=initializer,\n",
        "      padding='VALID',\n",
        "      trainable=trainable,\n",
        "      activation_fn=tf.nn.relu,\n",
        "      normalizer_fn=normalizer_fn,\n",
        "      normalizer_params=batch_norm_params):\n",
        "    with slim.arg_scope([slim.batch_norm], **batch_norm_params):\n",
        "      with slim.arg_scope([slim.batch_norm], is_training=is_model_training) as arg_sc:\n",
        "        return arg_sc\n",
        "\n",
        "\n",
        "def convolutional_alexnet(inputs, reuse=None, scope='convolutional_alexnet'):\n",
        "  \"\"\"Defines the feature extractor of SiamFC.\n",
        "  Args:\n",
        "    inputs: a Tensor of shape [batch, h, w, c].\n",
        "    reuse: if the weights in the embedding function are reused.\n",
        "    scope: the variable scope of the computational graph.\n",
        "  Returns:\n",
        "    net: the computed features of the inputs.\n",
        "    end_points: the intermediate outputs of the embedding function.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope(scope, 'convolutional_alexnet', [inputs], reuse=reuse) as sc:\n",
        "    end_points_collection = sc.name + '_end_points'\n",
        "    with slim.arg_scope([slim.conv2d, slim.max_pool2d],\n",
        "                        outputs_collections=end_points_collection):\n",
        "      net = inputs\n",
        "      net = slim.conv2d(net, 96, [11, 11], 2, scope='conv1')\n",
        "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool1')\n",
        "      with tf.variable_scope('conv2'):\n",
        "        b1, b2 = tf.split(net, 2, 3)\n",
        "        b1 = slim.conv2d(b1, 128, [5, 5], scope='b1')\n",
        "        # The original implementation has bias terms for all convolution, but\n",
        "        # it actually isn't necessary if the convolution layer is followed by a batch\n",
        "        # normalization layer since batch norm will subtract the mean.\n",
        "        b2 = slim.conv2d(b2, 128, [5, 5], scope='b2')\n",
        "        net = tf.concat([b1, b2], 3)\n",
        "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
        "      net = slim.conv2d(net, 384, [3, 3], 1, scope='conv3')\n",
        "      with tf.variable_scope('conv4'):\n",
        "        b1, b2 = tf.split(net, 2, 3)\n",
        "        b1 = slim.conv2d(b1, 192, [3, 3], 1, scope='b1')\n",
        "        b2 = slim.conv2d(b2, 192, [3, 3], 1, scope='b2')\n",
        "        net = tf.concat([b1, b2], 3)\n",
        "      # Conv 5 with only convolution, has bias\n",
        "      with tf.variable_scope('conv5'):\n",
        "        with slim.arg_scope([slim.conv2d],\n",
        "                            activation_fn=None, normalizer_fn=None):\n",
        "          b1, b2 = tf.split(net, 2, 3)\n",
        "          b1 = slim.conv2d(b1, 128, [3, 3], 1, scope='b1')\n",
        "          b2 = slim.conv2d(b2, 128, [3, 3], 1, scope='b2')\n",
        "        net = tf.concat([b1, b2], 3)\n",
        "      # Convert end_points_collection into a dictionary of end_points.\n",
        "      end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
        "      return net, end_points\n",
        "\n",
        "\n",
        "convolutional_alexnet.stride = 8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VMMLf8FxbmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Copyright Â© 2017 bily     Huazhong University of Science and Technology\n",
        "#\n",
        "# Distributed under terms of the MIT license.\n",
        "\n",
        "\"\"\"Utilities for model construction\"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from scipy import io as sio\n",
        "\n",
        "\n",
        "\n",
        "def construct_gt_score_maps(response_size, batch_size, stride, gt_config=None):\n",
        "  \"\"\"Construct a batch of groundtruth score maps\n",
        "  Args:\n",
        "    response_size: A list or tuple with two elements [ho, wo]\n",
        "    batch_size: An integer e.g., 16\n",
        "    stride: Embedding stride e.g., 8\n",
        "    gt_config: Configurations for groundtruth generation\n",
        "  Return:\n",
        "    A float tensor of shape [batch_size] + response_size\n",
        "  \"\"\"\n",
        "  with tf.name_scope('construct_gt'):\n",
        "    ho = response_size[0]\n",
        "    wo = response_size[1]\n",
        "    y = tf.cast(tf.range(0, ho), dtype=tf.float32) - get_center(ho)\n",
        "    x = tf.cast(tf.range(0, wo), dtype=tf.float32) - get_center(wo)\n",
        "    [Y, X] = tf.meshgrid(y, x)\n",
        "\n",
        "    def _logistic_label(X, Y, rPos, rNeg):\n",
        "      # dist_to_center = tf.sqrt(tf.square(X) + tf.square(Y))  # L2 metric\n",
        "      dist_to_center = tf.abs(X) + tf.abs(Y)  # Block metric\n",
        "      Z = tf.where(dist_to_center <= rPos,\n",
        "                   tf.ones_like(X),\n",
        "                   tf.where(dist_to_center < rNeg,\n",
        "                            0.5 * tf.ones_like(X),\n",
        "                            tf.zeros_like(X)))\n",
        "      return Z\n",
        "\n",
        "    rPos = gt_config['rPos'] / stride\n",
        "    rNeg = gt_config['rNeg'] / stride\n",
        "    gt = _logistic_label(X, Y, rPos, rNeg)\n",
        "\n",
        "    # Duplicate a batch of maps\n",
        "    gt_expand = tf.reshape(gt, [1] + response_size)\n",
        "    gt = tf.tile(gt_expand, [batch_size, 1, 1])\n",
        "    return gt\n",
        "\n",
        "\n",
        "def get_params_from_mat(matpath):\n",
        "  \"\"\"Get parameter from .mat file into parms(dict)\"\"\"\n",
        "\n",
        "  def squeeze(vars_):\n",
        "    # Matlab save some params with shape (*, 1)\n",
        "    # However, we don't need the trailing dimension in TensorFlow.\n",
        "    if isinstance(vars_, (list, tuple)):\n",
        "      return [np.squeeze(v, 1) for v in vars_]\n",
        "    else:\n",
        "      return np.squeeze(vars_, 1)\n",
        "\n",
        "  netparams = sio.loadmat(matpath)[\"net\"][\"params\"][0][0]\n",
        "  params = dict()\n",
        "\n",
        "  for i in range(netparams.size):\n",
        "    param = netparams[0][i]\n",
        "    name = param[\"name\"][0]\n",
        "    value = param[\"value\"]\n",
        "    value_size = param[\"value\"].shape[0]\n",
        "\n",
        "    match = re.match(r\"([a-z]+)([0-9]+)([a-z]+)\", name, re.I)\n",
        "    if match:\n",
        "      items = match.groups()\n",
        "    elif name == 'adjust_f':\n",
        "      params['detection/weights'] = squeeze(value)\n",
        "      continue\n",
        "    elif name == 'adjust_b':\n",
        "      params['detection/biases'] = squeeze(value)\n",
        "      continue\n",
        "    else:\n",
        "      raise Exception('unrecognized layer params')\n",
        "\n",
        "    op, layer, types = items\n",
        "    layer = int(layer)\n",
        "    if layer in [1, 3]:\n",
        "      if op == 'conv':  # convolution\n",
        "        if types == 'f':\n",
        "          params['conv%d/weights' % layer] = value\n",
        "        elif types == 'b':\n",
        "          value = squeeze(value)\n",
        "          params['conv%d/biases' % layer] = value\n",
        "      elif op == 'bn':  # batch normalization\n",
        "        if types == 'x':\n",
        "          m, v = squeeze(np.split(value, 2, 1))\n",
        "          params['conv%d/BatchNorm/moving_mean' % layer] = m\n",
        "          params['conv%d/BatchNorm/moving_variance' % layer] = np.square(v)\n",
        "        elif types == 'm':\n",
        "          value = squeeze(value)\n",
        "          params['conv%d/BatchNorm/gamma' % layer] = value\n",
        "        elif types == 'b':\n",
        "          value = squeeze(value)\n",
        "          params['conv%d/BatchNorm/beta' % layer] = value\n",
        "      else:\n",
        "        raise Exception\n",
        "    elif layer in [2, 4]:\n",
        "      if op == 'conv' and types == 'f':\n",
        "        b1, b2 = np.split(value, 2, 3)\n",
        "      else:\n",
        "        b1, b2 = np.split(value, 2, 0)\n",
        "      if op == 'conv':\n",
        "        if types == 'f':\n",
        "          params['conv%d/b1/weights' % layer] = b1\n",
        "          params['conv%d/b2/weights' % layer] = b2\n",
        "        elif types == 'b':\n",
        "          b1, b2 = squeeze(np.split(value, 2, 0))\n",
        "          params['conv%d/b1/biases' % layer] = b1\n",
        "          params['conv%d/b2/biases' % layer] = b2\n",
        "      elif op == 'bn':\n",
        "        if types == 'x':\n",
        "          m1, v1 = squeeze(np.split(b1, 2, 1))\n",
        "          m2, v2 = squeeze(np.split(b2, 2, 1))\n",
        "          params['conv%d/b1/BatchNorm/moving_mean' % layer] = m1\n",
        "          params['conv%d/b2/BatchNorm/moving_mean' % layer] = m2\n",
        "          params['conv%d/b1/BatchNorm/moving_variance' % layer] = np.square(v1)\n",
        "          params['conv%d/b2/BatchNorm/moving_variance' % layer] = np.square(v2)\n",
        "        elif types == 'm':\n",
        "          params['conv%d/b1/BatchNorm/gamma' % layer] = squeeze(b1)\n",
        "          params['conv%d/b2/BatchNorm/gamma' % layer] = squeeze(b2)\n",
        "        elif types == 'b':\n",
        "          params['conv%d/b1/BatchNorm/beta' % layer] = squeeze(b1)\n",
        "          params['conv%d/b2/BatchNorm/beta' % layer] = squeeze(b2)\n",
        "      else:\n",
        "        raise Exception\n",
        "\n",
        "    elif layer in [5]:\n",
        "      if op == 'conv' and types == 'f':\n",
        "        b1, b2 = np.split(value, 2, 3)\n",
        "      else:\n",
        "        b1, b2 = squeeze(np.split(value, 2, 0))\n",
        "      assert op == 'conv', 'layer5 contains only convolution'\n",
        "      if types == 'f':\n",
        "        params['conv%d/b1/weights' % layer] = b1\n",
        "        params['conv%d/b2/weights' % layer] = b2\n",
        "      elif types == 'b':\n",
        "        params['conv%d/b1/biases' % layer] = b1\n",
        "        params['conv%d/b2/biases' % layer] = b2\n",
        "\n",
        "  return params\n",
        "\n",
        "\n",
        "def load_mat_model(matpath, embed_scope, detection_scope=None):\n",
        "  \"\"\"Restore SiameseFC models from .mat model files\"\"\"\n",
        "  params = get_params_from_mat(matpath)\n",
        "\n",
        "  assign_ops = []\n",
        "\n",
        "  def _assign(ref_name, params, scope=embed_scope):\n",
        "    var_in_model = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
        "                                     scope + ref_name)[0]\n",
        "    var_in_mat = params[ref_name]\n",
        "    op = tf.assign(var_in_model, var_in_mat)\n",
        "    assign_ops.append(op)\n",
        "\n",
        "  for l in range(1, 6):\n",
        "    if l in [1, 3]:\n",
        "      _assign('conv%d/weights' % l, params)\n",
        "      # _assign('conv%d/biases' % l, params)\n",
        "      _assign('conv%d/BatchNorm/beta' % l, params)\n",
        "      _assign('conv%d/BatchNorm/gamma' % l, params)\n",
        "      _assign('conv%d/BatchNorm/moving_mean' % l, params)\n",
        "      _assign('conv%d/BatchNorm/moving_variance' % l, params)\n",
        "    elif l in [2, 4]:\n",
        "      # Branch 1\n",
        "      _assign('conv%d/b1/weights' % l, params)\n",
        "      # _assign('conv%d/b1/biases' % l, params)\n",
        "      _assign('conv%d/b1/BatchNorm/beta' % l, params)\n",
        "      _assign('conv%d/b1/BatchNorm/gamma' % l, params)\n",
        "      _assign('conv%d/b1/BatchNorm/moving_mean' % l, params)\n",
        "      _assign('conv%d/b1/BatchNorm/moving_variance' % l, params)\n",
        "      # Branch 2\n",
        "      _assign('conv%d/b2/weights' % l, params)\n",
        "      # _assign('conv%d/b2/biases' % l, params)\n",
        "      _assign('conv%d/b2/BatchNorm/beta' % l, params)\n",
        "      _assign('conv%d/b2/BatchNorm/gamma' % l, params)\n",
        "      _assign('conv%d/b2/BatchNorm/moving_mean' % l, params)\n",
        "      _assign('conv%d/b2/BatchNorm/moving_variance' % l, params)\n",
        "    elif l in [5]:\n",
        "      # Branch 1\n",
        "      _assign('conv%d/b1/weights' % l, params)\n",
        "      _assign('conv%d/b1/biases' % l, params)\n",
        "      # Branch 2\n",
        "      _assign('conv%d/b2/weights' % l, params)\n",
        "      _assign('conv%d/b2/biases' % l, params)\n",
        "    else:\n",
        "      raise Exception('layer number must below 5')\n",
        "\n",
        "  if detection_scope:\n",
        "    _assign(detection_scope + 'biases', params, scope='')\n",
        "\n",
        "  initialize = tf.group(*assign_ops)\n",
        "  return initialize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdznsVczxmdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Copyright Â© 2017 bily     Huazhong University of Science and Technology\n",
        "#\n",
        "# Distributed under terms of the MIT license.\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops.metrics_impl import _confusion_matrix_at_thresholds\n",
        "\n",
        "\n",
        "def _auc(labels, predictions, weights=None, num_thresholds=200,\n",
        "         metrics_collections=None, updates_collections=None,\n",
        "         curve='ROC', name=None, summation_method='trapezoidal'):\n",
        "  \"\"\"Computes the approximate AUC via a Riemann sum.\n",
        "  Modified version of tf.metrics.auc. Add support for AUC computation\n",
        "  of the recall curve.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope(\n",
        "      name, 'auc', (labels, predictions, weights)):\n",
        "    if curve != 'ROC' and curve != 'PR' and curve != 'R':\n",
        "      raise ValueError('curve must be either ROC, PR or R, %s unknown' %\n",
        "                       (curve))\n",
        "    kepsilon = 1e-7  # to account for floating point imprecisions\n",
        "    thresholds = [(i + 1) * 1.0 / (num_thresholds - 1)\n",
        "                  for i in range(num_thresholds - 2)]\n",
        "    thresholds = [0.0 - kepsilon] + thresholds + [1.0 + kepsilon]\n",
        "\n",
        "    values, update_ops = _confusion_matrix_at_thresholds(\n",
        "      labels, predictions, thresholds, weights)\n",
        "\n",
        "    # Add epsilons to avoid dividing by 0.\n",
        "    epsilon = 1.0e-6\n",
        "\n",
        "    def compute_auc(tp, fn, tn, fp, name):\n",
        "      \"\"\"Computes the roc-auc or pr-auc based on confusion counts.\"\"\"\n",
        "      rec = tf.div(tp + epsilon, tp + fn + epsilon)\n",
        "      if curve == 'ROC':\n",
        "        fp_rate = tf.div(fp, fp + tn + epsilon)\n",
        "        x = fp_rate\n",
        "        y = rec\n",
        "      elif curve == 'R':  # recall auc\n",
        "        x = tf.linspace(1., 0., num_thresholds)\n",
        "        y = rec\n",
        "      else:  # curve == 'PR'.\n",
        "        prec = tf.div(tp + epsilon, tp + fp + epsilon)\n",
        "        x = rec\n",
        "        y = prec\n",
        "      if summation_method == 'trapezoidal':\n",
        "        return tf.reduce_sum(\n",
        "          tf.multiply(x[:num_thresholds - 1] - x[1:],\n",
        "                      (y[:num_thresholds - 1] + y[1:]) / 2.),\n",
        "          name=name)\n",
        "      elif summation_method == 'minoring':\n",
        "        return tf.reduce_sum(\n",
        "          tf.multiply(x[:num_thresholds - 1] - x[1:],\n",
        "                      tf.minimum(y[:num_thresholds - 1], y[1:])),\n",
        "          name=name)\n",
        "      elif summation_method == 'majoring':\n",
        "        return tf.reduce_sum(\n",
        "          tf.multiply(x[:num_thresholds - 1] - x[1:],\n",
        "                      tf.maximum(y[:num_thresholds - 1], y[1:])),\n",
        "          name=name)\n",
        "      else:\n",
        "        raise ValueError('Invalid summation_method: %s' % summation_method)\n",
        "\n",
        "    # sum up the areas of all the trapeziums\n",
        "    auc_value = compute_auc(\n",
        "      values['tp'], values['fn'], values['tn'], values['fp'], 'value')\n",
        "    update_op = compute_auc(\n",
        "      update_ops['tp'], update_ops['fn'], update_ops['tn'], update_ops['fp'],\n",
        "      'update_op')\n",
        "\n",
        "    if metrics_collections:\n",
        "      ops.add_to_collections(metrics_collections, auc_value)\n",
        "\n",
        "    if updates_collections:\n",
        "      ops.add_to_collections(updates_collections, update_op)\n",
        "\n",
        "    return auc_value, update_op\n",
        "\n",
        "\n",
        "def get_center_index(response):\n",
        "  \"\"\"Get the index of the center in the response map\"\"\"\n",
        "  shape = tf.shape(response)\n",
        "  c1 = tf.to_int32((shape[1] - 1) / 2)\n",
        "  c2 = tf.to_int32((shape[2] - 1) / 2)\n",
        "  return c1, c2\n",
        "\n",
        "\n",
        "def center_score_error(response):\n",
        "  \"\"\"Center score error.\n",
        "  The error is low when the center of the response map is classified as target.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('CS-err'):\n",
        "    r, c = get_center_index(response)\n",
        "    center_score = response[:, r, c]\n",
        "    mean, update_op = tf.metrics.mean(tf.to_float(center_score < 0))\n",
        "    with tf.control_dependencies([update_op]):\n",
        "      mean = tf.identity(mean)\n",
        "    return mean\n",
        "\n",
        "\n",
        "def get_maximum_index(response):\n",
        "  \"\"\"Get the index of the maximum value in the response map\"\"\"\n",
        "  response_shape = response.get_shape().as_list()\n",
        "  response_spatial_size = response_shape[-2:]  # e.g. [29, 29]\n",
        "  length = response_spatial_size[0] * response_spatial_size[1]\n",
        "\n",
        "  # Get maximum response index (note index starts from zero)\n",
        "  ind_max = tf.argmax(tf.reshape(response, [-1, length]), 1)\n",
        "  ind_row = tf.div(ind_max, response_spatial_size[1])\n",
        "  ind_col = tf.mod(ind_max, response_spatial_size[1])\n",
        "  return ind_row, ind_col\n",
        "\n",
        "\n",
        "def center_dist_error(response):\n",
        "  \"\"\"Center distance error.\n",
        "  The error is low when the maximum response is at the center of the response map.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('CD-err'):\n",
        "    radius_in_pixel = 50.\n",
        "    total_stride = 8.\n",
        "    num_thresholds = 100\n",
        "    radius_in_response = radius_in_pixel / total_stride\n",
        "\n",
        "    gt_r, gt_c = get_center_index(response)\n",
        "    max_r, max_c = get_maximum_index(response)\n",
        "    gt_r = tf.to_float(gt_r)\n",
        "    gt_c = tf.to_float(gt_c)\n",
        "    max_r = tf.to_float(max_r)\n",
        "    max_c = tf.to_float(max_c)\n",
        "    distances = tf.sqrt((gt_r - max_r) ** 2 + (gt_c - max_c) ** 2)\n",
        "\n",
        "    # We cast distances as prediction accuracies in the range [0, 1] where 0 means fail and\n",
        "    # 1 means success. In this way, we can readily use streaming_auc to compute area\n",
        "    # under curve.\n",
        "    dist_norm = distances / radius_in_response\n",
        "    dist_norm = tf.minimum(dist_norm, 1.)\n",
        "    predictions = 1. - dist_norm\n",
        "    labels = tf.ones_like(predictions)\n",
        "\n",
        "    auc, update_op = _auc(labels, predictions, num_thresholds=num_thresholds, curve='R')\n",
        "    with tf.control_dependencies([update_op]):\n",
        "      err = 1. - auc\n",
        "    return err"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWb2i1sDyCuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "35125e90-2a2f-47df-a4c3-deea816cc575"
      },
      "source": [
        "#! /usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Copyright Â© 2017 bily     Huazhong University of Science and Technology\n",
        "#\n",
        "# Distributed under terms of the MIT license.\n",
        "\n",
        "\"\"\"Dataset Sampler\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Sampler(object):\n",
        "  def __init__(self, data_source, shuffle=True):\n",
        "    self.data_source = data_source\n",
        "    self.shuffle = shuffle\n",
        "\n",
        "  def __iter__(self):\n",
        "    data_idxs = np.arange(len(self.data_source))\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(data_idxs)\n",
        "\n",
        "    for idx in data_idxs:\n",
        "      yield idx\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  x = [1, 2, 3]\n",
        "  sampler = Sampler(x, shuffle=True)\n",
        "  p = 0\n",
        "  for xx in sampler:\n",
        "    print(x[xx])\n",
        "    p += 1\n",
        "    if p == 10: break"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "3\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hume9y2j0fi7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Copyright Â© 2017 bily     Huazhong University of Science and Technology\n",
        "#\n",
        "# Distributed under terms of the MIT license.\n",
        "\n",
        "\n",
        "\"\"\"Various transforms for video and image augmentation\"\"\"\n",
        "\n",
        "import numbers\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class Compose(object):\n",
        "  \"\"\"Composes several transforms together.\"\"\"\n",
        "\n",
        "  def __init__(self, transforms):\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __call__(self, example):\n",
        "    for t in self.transforms:\n",
        "      example = t(example)\n",
        "    return example\n",
        "\n",
        "\n",
        "class RandomGray(object):\n",
        "  def __init__(self, gray_ratio=0.25):\n",
        "    self.gray_ratio = gray_ratio\n",
        "\n",
        "  def __call__(self, img_sequence):\n",
        "    def rgb_to_gray():\n",
        "      gray_images = tf.image.rgb_to_grayscale(img_sequence)\n",
        "      return tf.concat([gray_images] * 3, axis=3)\n",
        "\n",
        "    def identity():\n",
        "      return tf.identity(img_sequence)\n",
        "\n",
        "    return tf.cond(tf.less(tf.random_uniform([], 0, 1), self.gray_ratio), rgb_to_gray, identity)\n",
        "\n",
        "\n",
        "class RandomStretch(object):\n",
        "  def __init__(self, max_stretch=0.05, interpolation='bilinear'):\n",
        "    self.max_stretch = max_stretch\n",
        "    self.interpolation = interpolation\n",
        "\n",
        "  def __call__(self, img):\n",
        "    scale = 1.0 + tf.random_uniform([], -self.max_stretch, self.max_stretch)\n",
        "    img_shape = tf.shape(img)\n",
        "    ts = tf.to_int32(tf.round(tf.to_float(img_shape[:2]) * scale))\n",
        "    resize_method_map = {'bilinear': tf.image.ResizeMethod.BILINEAR,\n",
        "                         'bicubic': tf.image.ResizeMethod.BICUBIC}\n",
        "    return tf.image.resize_images(img, ts, method=resize_method_map[self.interpolation])\n",
        "\n",
        "\n",
        "class CenterCrop(object):\n",
        "  def __init__(self, size):\n",
        "    if isinstance(size, numbers.Number):\n",
        "      self.size = (int(size), int(size))\n",
        "    else:\n",
        "      self.size = size\n",
        "\n",
        "  def __call__(self, img):\n",
        "    th, tw = self.size\n",
        "    return tf.image.resize_image_with_crop_or_pad(img, th, tw)\n",
        "\n",
        "\n",
        "class RandomCrop(object):\n",
        "  def __init__(self, size):\n",
        "    if isinstance(size, numbers.Number):\n",
        "      self.size = (int(size), int(size))\n",
        "    else:\n",
        "      self.size = size\n",
        "\n",
        "  def __call__(self, img):\n",
        "    img_shape = tf.shape(img)\n",
        "    th, tw = self.size\n",
        "\n",
        "    y1 = tf.random_uniform([], 0, img_shape[0] - th, dtype=tf.int32)\n",
        "    x1 = tf.random_uniform([], 0, img_shape[1] - tw, dtype=tf.int32)\n",
        "\n",
        "    return tf.image.crop_to_bounding_box(img, y1, x1, th, tw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I6iMO0w06O2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Copyright Â© 2017 bily     Huazhong University of Science and Technology\n",
        "#\n",
        "# Distributed under terms of the MIT license.\n",
        "\n",
        "\"\"\"VID Dataset\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def downsample(n_in, n_out, max_frame_dist=1):\n",
        "  # Get a list of frame distance between consecutive frames\n",
        "  max_frame_dist = np.minimum(n_in, max_frame_dist)\n",
        "  possible_frame_dist = range(1, max_frame_dist + 1)\n",
        "  frame_dist = np.random.choice(possible_frame_dist, n_out - 1)\n",
        "  end_to_start_frame_dist = np.sum(frame_dist)\n",
        "\n",
        "  # Check frame dist boundary\n",
        "  possible_max_start_idx = n_in - 1 - end_to_start_frame_dist\n",
        "  if possible_max_start_idx < 0:\n",
        "    n_extra = - possible_max_start_idx\n",
        "    while n_extra > 0:\n",
        "      for idx, dist in enumerate(frame_dist):\n",
        "        if dist > 1:\n",
        "          frame_dist[idx] = dist - 1\n",
        "          n_extra -= 1\n",
        "          if n_extra == 0: break\n",
        "\n",
        "  # Get frame dist\n",
        "  end_to_start_frame_dist = np.sum(frame_dist)\n",
        "  possible_max_start_idx = n_in - 1 - end_to_start_frame_dist\n",
        "  start_idx = np.random.choice(possible_max_start_idx + 1, 1)\n",
        "  out_idxs = np.cumsum(np.concatenate((start_idx, frame_dist)))\n",
        "  return out_idxs\n",
        "\n",
        "\n",
        "def upsample(n_in, n_out):\n",
        "  n_more = n_out - n_in\n",
        "  in_idxs = range(n_in)\n",
        "  more_idxs = np.random.choice(in_idxs, n_more)\n",
        "  out_idxs = sorted(list(in_idxs) + list(more_idxs))\n",
        "  return out_idxs\n",
        "\n",
        "\n",
        "class VID:\n",
        "  def __init__(self, imdb_path, max_frame_dist, epoch_size=None):\n",
        "    with open(imdb_path, 'rb') as f:\n",
        "      imdb = pickle.load(f)\n",
        "\n",
        "    self.videos = imdb['videos']\n",
        "    self.time_steps = 2\n",
        "    self.max_frame_dist = max_frame_dist\n",
        "\n",
        "    if epoch_size is None:\n",
        "      self.epoch_size = len(self.videos)\n",
        "    else:\n",
        "      self.epoch_size = int(epoch_size)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    img_ids = self.videos[index % len(self.videos)]\n",
        "    n_frames = len(img_ids)\n",
        "\n",
        "    if n_frames < self.time_steps:\n",
        "      out_idxs = upsample(n_frames, self.time_steps)\n",
        "    elif n_frames == self.time_steps:\n",
        "      out_idxs = range(n_frames)\n",
        "    else:\n",
        "      out_idxs = downsample(n_frames, self.time_steps, self.max_frame_dist)\n",
        "\n",
        "    video = []\n",
        "    for j, frame_idx in enumerate(out_idxs):\n",
        "      img_path = img_ids[frame_idx]\n",
        "      video.append(img_path.encode('utf-8'))\n",
        "    return video\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.epoch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMY4l8761HQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! /usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Copyright Â© 2017 bily     Huazhong University of Science and Technology\n",
        "#\n",
        "# Distributed under terms of the MIT license.\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "class DataLoader(object):\n",
        "  def __init__(self, config, is_training):\n",
        "    self.config = config\n",
        "    self.is_training = is_training\n",
        "\n",
        "    preprocess_name = get(config, 'preprocessing_name', None)\n",
        "    logging.info('preproces -- {}'.format(preprocess_name))\n",
        "\n",
        "    if preprocess_name == 'siamese_fc_color':\n",
        "      self.v_transform = None\n",
        "      # TODO: use a single operation (tf.image.crop_and_resize) to achieve all transformations ?\n",
        "      self.z_transform = Compose([RandomStretch(),\n",
        "                                  CenterCrop((255 - 8, 255 - 8)),\n",
        "                                  RandomCrop(255 - 2 * 8),\n",
        "                                  CenterCrop((127, 127))])\n",
        "      self.x_transform = Compose([RandomStretch(),\n",
        "                                  CenterCrop((255 - 8, 255 - 8)),\n",
        "                                  RandomCrop(255 - 2 * 8), ])\n",
        "    elif preprocess_name == 'siamese_fc_gray':\n",
        "      self.v_transform = RandomGray()\n",
        "      self.z_transform = Compose([RandomStretch(),\n",
        "                                  CenterCrop((255 - 8, 255 - 8)),\n",
        "                                  RandomCrop(255 - 2 * 8),\n",
        "                                  CenterCrop((127, 127))])\n",
        "      self.x_transform = Compose([RandomStretch(),\n",
        "                                  CenterCrop((255 - 8, 255 - 8)),\n",
        "                                  RandomCrop(255 - 2 * 8), ])\n",
        "    elif preprocess_name == 'None':\n",
        "      self.v_transform = None\n",
        "      self.z_transform = CenterCrop((127, 127))\n",
        "      self.x_transform = CenterCrop((255, 255))\n",
        "    else:\n",
        "      raise ValueError('Preprocessing name {} was not recognized.'.format(preprocess_name))\n",
        "\n",
        "    self.dataset_py = VID(config['input_imdb'], config['max_frame_dist'])\n",
        "    self.sampler = Sampler(self.dataset_py, shuffle=is_training)\n",
        "\n",
        "  def build(self):\n",
        "    self.build_dataset()\n",
        "    self.build_iterator()\n",
        "\n",
        "  def build_dataset(self):\n",
        "    def sample_generator():\n",
        "      for video_id in self.sampler:\n",
        "        sample = self.dataset_py[video_id]\n",
        "        yield sample\n",
        "\n",
        "    def transform_fn(video):\n",
        "      exemplar_file = tf.read_file(video[0])\n",
        "      instance_file = tf.read_file(video[1])\n",
        "      exemplar_image = tf.image.decode_jpeg(exemplar_file, channels=3, dct_method=\"INTEGER_ACCURATE\")\n",
        "      instance_image = tf.image.decode_jpeg(instance_file, channels=3, dct_method=\"INTEGER_ACCURATE\")\n",
        "\n",
        "      if self.v_transform is not None:\n",
        "        video = tf.stack([exemplar_image, instance_image])\n",
        "        video = self.v_transform(video)\n",
        "        exemplar_image = video[0]\n",
        "        instance_image = video[1]\n",
        "\n",
        "      if self.z_transform is not None:\n",
        "        exemplar_image = self.z_transform(exemplar_image)\n",
        "\n",
        "      if self.x_transform is not None:\n",
        "        instance_image = self.x_transform(instance_image)\n",
        "\n",
        "      return exemplar_image, instance_image\n",
        "\n",
        "    dataset = tf.data.Dataset.from_generator(sample_generator,\n",
        "                                             output_types=(tf.string),\n",
        "                                             output_shapes=(tf.TensorShape([2])))\n",
        "    dataset = dataset.map(transform_fn, num_parallel_calls=self.config['prefetch_threads'])\n",
        "    dataset = dataset.prefetch(self.config['prefetch_capacity'])\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(self.config['batch_size'])\n",
        "    self.dataset_tf = dataset\n",
        "\n",
        "  def build_iterator(self):\n",
        "    self.iterator = self.dataset_tf.make_one_shot_iterator()\n",
        "\n",
        "  def get_one_batch(self):\n",
        "    return self.iterator.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9-phA6L1WWq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "8678333b-c1af-4488-eacd-99512350e14f"
      },
      "source": [
        "#! /usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "#\n",
        "# Copyright Â© 2017 bily     Huazhong University of Science and Technology\n",
        "#\n",
        "# Distributed under terms of the MIT license.\n",
        "\n",
        "\"\"\"Construct the computational graph of siamese model for training. \"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import functools\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "\n",
        "\n",
        "class SiameseModel:\n",
        "  def __init__(self, model_config, train_config, mode='train'):\n",
        "    self.model_config = model_config\n",
        "    self.train_config = train_config\n",
        "    self.mode = mode\n",
        "    assert mode in ['train', 'validation', 'inference']\n",
        "\n",
        "    if self.mode == 'train':\n",
        "      self.data_config = self.train_config['train_data_config']\n",
        "    elif self.mode == 'validation':\n",
        "      self.data_config = self.train_config['validation_data_config']\n",
        "\n",
        "    self.dataloader = None\n",
        "    self.exemplars = None\n",
        "    self.instances = None\n",
        "    self.response = None\n",
        "    self.batch_loss = None\n",
        "    self.total_loss = None\n",
        "    self.init_fn = None\n",
        "    self.global_step = None\n",
        "\n",
        "  def is_training(self):\n",
        "    \"\"\"Returns true if the model is built for training mode\"\"\"\n",
        "    return self.mode == 'train'\n",
        "\n",
        "  def build_inputs(self):\n",
        "    \"\"\"Input fetching and batching\n",
        "    Outputs:\n",
        "      self.exemplars: image batch of shape [batch, hz, wz, 3]\n",
        "      self.instances: image batch of shape [batch, hx, wx, 3]\n",
        "    \"\"\"\n",
        "    if self.mode in ['train', 'validation']:\n",
        "      with tf.device(\"/cpu:0\"):  # Put data loading and preprocessing in CPU is substantially faster\n",
        "        self.dataloader = DataLoader(self.data_config, self.is_training())\n",
        "        self.dataloader.build()\n",
        "        exemplars, instances = self.dataloader.get_one_batch()\n",
        "\n",
        "        exemplars = tf.to_float(exemplars)\n",
        "        instances = tf.to_float(instances)\n",
        "    else:\n",
        "      self.examplar_feed = tf.placeholder(shape=[None, None, None, 3],\n",
        "                                          dtype=tf.uint8,\n",
        "                                          name='examplar_input')\n",
        "      self.instance_feed = tf.placeholder(shape=[None, None, None, 3],\n",
        "                                          dtype=tf.uint8,\n",
        "                                          name='instance_input')\n",
        "      exemplars = tf.to_float(self.examplar_feed)\n",
        "      instances = tf.to_float(self.instance_feed)\n",
        "\n",
        "    self.exemplars = exemplars\n",
        "    self.instances = instances\n",
        "\n",
        "  def build_image_embeddings(self, reuse=False):\n",
        "    \"\"\"Builds the image model subgraph and generates image embeddings\n",
        "    Inputs:\n",
        "      self.exemplars: A tensor of shape [batch, hz, wz, 3]\n",
        "      self.instances: A tensor of shape [batch, hx, wx, 3]\n",
        "    Outputs:\n",
        "      self.exemplar_embeds: A Tensor of shape [batch, hz_embed, wz_embed, embed_dim]\n",
        "      self.instance_embeds: A Tensor of shape [batch, hx_embed, wx_embed, embed_dim]\n",
        "    \"\"\"\n",
        "    config = self.model_config['embed_config']\n",
        "    arg_scope = convolutional_alexnet_arg_scope(config,\n",
        "                                                trainable=config['train_embedding'],\n",
        "                                                is_training=self.is_training())\n",
        "\n",
        "    @functools.wraps(convolutional_alexnet)\n",
        "    def embedding_fn(images, reuse=False):\n",
        "      with slim.arg_scope(arg_scope):\n",
        "        return convolutional_alexnet(images, reuse=reuse)\n",
        "\n",
        "    self.exemplar_embeds, _ = embedding_fn(self.exemplars, reuse=reuse)\n",
        "    self.instance_embeds, _ = embedding_fn(self.instances, reuse=True)\n",
        "\n",
        "  def build_template(self):\n",
        "    # The template is simply the feature of the exemplar image in SiamFC.\n",
        "    self.templates = self.exemplar_embeds\n",
        "\n",
        "  def build_detection(self, reuse=False):\n",
        "    with tf.variable_scope('detection', reuse=reuse):\n",
        "      def _translation_match(x, z):  # translation match for one example within a batch\n",
        "        x = tf.expand_dims(x, 0)  # [1, in_height, in_width, in_channels]\n",
        "        z = tf.expand_dims(z, -1)  # [filter_height, filter_width, in_channels, 1]\n",
        "        return tf.nn.conv2d(x, z, strides=[1, 1, 1, 1], padding='VALID', name='translation_match')\n",
        "\n",
        "      output = tf.map_fn(lambda x: _translation_match(x[0], x[1]),\n",
        "                         (self.instance_embeds, self.templates),\n",
        "                         dtype=self.instance_embeds.dtype)\n",
        "      output = tf.squeeze(output, [1, 4])  # of shape e.g., [8, 15, 15]\n",
        "\n",
        "      # Adjust score, this is required to make training possible.\n",
        "      config = self.model_config['adjust_response_config']\n",
        "      bias = tf.get_variable('biases', [1],\n",
        "                             dtype=tf.float32,\n",
        "                             initializer=tf.constant_initializer(0.0, dtype=tf.float32),\n",
        "                             trainable=config['train_bias'])\n",
        "      response = config['scale'] * output + bias\n",
        "      self.response = response\n",
        "\n",
        "  def build_loss(self):\n",
        "    response = self.response\n",
        "    response_size = response.get_shape().as_list()[1:3]  # [height, width]\n",
        "\n",
        "    gt = construct_gt_score_maps(response_size,\n",
        "                                 self.data_config['batch_size'],\n",
        "                                 self.model_config['embed_config']['stride'],\n",
        "                                 self.train_config['gt_config'])\n",
        "\n",
        "    with tf.name_scope('Loss'):\n",
        "      loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=response,\n",
        "                                                     labels=gt)\n",
        "\n",
        "      with tf.name_scope('Balance_weights'):\n",
        "        n_pos = tf.reduce_sum(tf.to_float(tf.equal(gt[0], 1)))\n",
        "        n_neg = tf.reduce_sum(tf.to_float(tf.equal(gt[0], 0)))\n",
        "        w_pos = 0.5 / n_pos\n",
        "        w_neg = 0.5 / n_neg\n",
        "        class_weights = tf.where(tf.equal(gt, 1),\n",
        "                                 w_pos * tf.ones_like(gt),\n",
        "                                 tf.ones_like(gt))\n",
        "        class_weights = tf.where(tf.equal(gt, 0),\n",
        "                                 w_neg * tf.ones_like(gt),\n",
        "                                 class_weights)\n",
        "        loss = loss * class_weights\n",
        "\n",
        "      # Note that we use reduce_sum instead of reduce_mean since the loss has\n",
        "      # already been normalized by class_weights in spatial dimension.\n",
        "      loss = tf.reduce_sum(loss, [1, 2])\n",
        "\n",
        "      batch_loss = tf.reduce_mean(loss, name='batch_loss')\n",
        "      tf.losses.add_loss(batch_loss)\n",
        "\n",
        "      total_loss = tf.losses.get_total_loss()\n",
        "      self.batch_loss = batch_loss\n",
        "      self.total_loss = total_loss\n",
        "\n",
        "      tf.summary.image('exemplar', self.exemplars, family=self.mode)\n",
        "      tf.summary.image('instance', self.instances, family=self.mode)\n",
        "\n",
        "      mean_batch_loss, update_op1 = tf.metrics.mean(batch_loss)\n",
        "      mean_total_loss, update_op2 = tf.metrics.mean(total_loss)\n",
        "      with tf.control_dependencies([update_op1, update_op2]):\n",
        "        tf.summary.scalar('batch_loss', mean_batch_loss, family=self.mode)\n",
        "        tf.summary.scalar('total_loss', mean_total_loss, family=self.mode)\n",
        "\n",
        "      if self.mode == 'train':\n",
        "        tf.summary.image('GT', tf.reshape(gt[0], [1] + response_size + [1]), family='GT')\n",
        "      tf.summary.image('Response', tf.expand_dims(tf.sigmoid(response), -1), family=self.mode)\n",
        "      tf.summary.histogram('Response', self.response, family=self.mode)\n",
        "\n",
        "      # Two more metrics to monitor the performance of training\n",
        "      tf.summary.scalar('center_score_error', center_score_error(response), family=self.mode)\n",
        "      tf.summary.scalar('center_dist_error', center_dist_error(response), family=self.mode)\n",
        "\n",
        "  def setup_global_step(self):\n",
        "    global_step = tf.Variable(\n",
        "      initial_value=0,\n",
        "      name='global_step',\n",
        "      trainable=False,\n",
        "      collections=[tf.GraphKeys.GLOBAL_STEP, tf.GraphKeys.GLOBAL_VARIABLES])\n",
        "\n",
        "    self.global_step = global_step\n",
        "\n",
        "  def setup_embedding_initializer(self):\n",
        "    \"\"\"Sets up the function to restore embedding variables from checkpoint.\"\"\"\n",
        "    embed_config = self.model_config['embed_config']\n",
        "    if embed_config['embedding_checkpoint_file']:\n",
        "      # Restore Siamese FC models from .mat model files\n",
        "      initialize = load_mat_model(embed_config['embedding_checkpoint_file'],\n",
        "                                  'convolutional_alexnet/', 'detection/')\n",
        "\n",
        "      def restore_fn(sess):\n",
        "        tf.logging.info(\"Restoring embedding variables from checkpoint file %s\",\n",
        "                        embed_config['embedding_checkpoint_file'])\n",
        "        sess.run([initialize])\n",
        "\n",
        "      self.init_fn = restore_fn\n",
        "\n",
        "  def build(self, reuse=False):\n",
        "    \"\"\"Creates all ops for training and evaluation\"\"\"\n",
        "    with tf.name_scope(self.mode):\n",
        "      self.build_inputs()\n",
        "      self.build_image_embeddings(reuse=reuse)\n",
        "      self.build_template()\n",
        "      self.build_detection(reuse=reuse)\n",
        "      self.setup_embedding_initializer()\n",
        "\n",
        "      if self.mode in ['train', 'validation']:\n",
        "        self.build_loss()\n",
        "\n",
        "      if self.is_training():\n",
        "        self.setup_global_step()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-86e0f7820af9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mslim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
          ]
        }
      ]
    }
  ]
}